// modules/batch-sync.js
// Batch synchronization module for efficient bulk operations

/* eslint-disable nodus/require-async-orchestration */

import { DateCore } from "@shared/lib/DateUtils.js";

/**
 * @file batch-sync.js
 * @version 8.0.0
 * @description Enterprise batch synchronization module with pluggable strategies.
 * Provides automatic observability, conflict resolution, and policy-compliant sync operations.
 * All sync operations flow through orchestrated patterns for complete audit trails,
 * performance monitoring, and security compliance.
 *
 * @description
 * Manages high-volume data synchronization through efficient batching of operations.
 * This module is crucial for offline-first scenarios, reducing network requests by
 * grouping multiple data changes (items) into single push or pull operations.
 * It includes features like automatic batching by size or age, parallel processing,
 * and optional payload compression.
 *
 * @module BatchSync
 *
 * @privateFields {#config, #pendingBatches, #syncQueue, #batchProcessorInterval, #stateManager, #managers, #errorBoundary, #metrics, #policies, #actionDispatcher, #orchestratorRunner, #AppError, #PolicyError}
 */
export default class BatchSync {
	/** @private @type {object} */
	#config;
	/** @private @type {Map<string, object>} */
	#pendingBatches = new Map();
	/** @private @type {Array<object>} */
	#syncQueue = [];
	/** @private @type {number|null} */
	#batchProcessorInterval = null;
	/** @private @type {import('../../HybridStateManager.js').default} */
	#stateManager;
	/** @private @type {object} */
	#managers;
	/** @private @type {import('@shared/lib/ErrorHelpers.js').ErrorBoundary|null} */
	#errorBoundary = null;
	/** @private @type {import('../../../utils/MetricsRegistry.js').MetricsRegistry|null} */
	#metrics = null;
	/** @private @type {import('@platform/policies/PolicyEngineAdapter.js').default|null} */
	#policies = null;
	/** @private @type {import('@platform/actions/ActionDispatcher.js').default|null} */
	#actionDispatcher = null;
	/** @private @type {ReturnType<import('@shared/lib/async/AsyncOrchestrationService.js').AsyncOrchestrationService["createRunner"]>} */
	#orchestratorRunner;
	/** @private @type {ErrorConstructor} */
	#AppError;
	/** @private @type {ErrorConstructor} */
	#PolicyError;

	/** @public @type {string} */
	name = "BatchSync";
	/** @public @type {boolean} */
	supportsPush = true;
	/** @public @type {boolean} */
	supportsPull = true;

	/**
	 * Creates an instance of BatchSync.
	 * @param {object} context - The application context.
	 * @param {import('../../HybridStateManager.js').default} context.stateManager - The main state manager instance.
	 * @param {object} [context.options={}] - Configuration options for the batch sync module.
	 * @param {number} [options.batchSize=100] - The maximum number of items in a single batch.
	 * @param {number} [options.maxBatchAge=30000] - The maximum age of a batch in milliseconds before it's automatically processed.
	 * @param {number} [options.compressionThreshold=1024] - The payload size in bytes above which compression is attempted.
	 * @param {boolean} [options.enableCompression=true] - Whether to enable payload compression.
	 * @param {number} [options.retryAttempts=3] - The number of times to retry a failed batch.
	 * @param {number} [options.parallelBatches=3] - The number of batches to process in parallel.
	 * @param {number} [options.offlineQueueLimit=5000] - The maximum number of items to hold in the offline queue.
	 */
	/**

	 * TODO: Add JSDoc for method constructor

	 * @memberof AutoGenerated

	 */

	constructor({ stateManager, options = {} }) {
		this.#stateManager = stateManager;

		// V8.0 Parity: Mandate 1.2 - Derive all dependencies from stateManager
		this.#managers = stateManager?.managers || {};
		this.#AppError = this.#managers?.errorHelpers?.AppError || Error;
		this.#PolicyError = this.#managers?.errorHelpers?.PolicyError || Error;
		this.#errorBoundary =
			this.#managers?.errorHelpers?.createErrorBoundary(
				{
					name: "BatchSync",
					managers: this.#managers,
				},
				"BatchSync"
			) || null;
		this.#metrics =
			this.#stateManager?.metricsRegistry?.namespace("batchSync");
		this.#policies = this.#managers?.policies || null;
		this.#actionDispatcher = this.#managers?.actionDispatcher || null;

		this.#config = {
			batchSize: options.batchSize || 100,
			maxBatchAge: options.maxBatchAge || 30000, // 30 seconds
			compressionThreshold: options.compressionThreshold || 1024, // 1KB
			enableCompression: options.enableCompression !== false,
			retryAttempts: options.retryAttempts || 3,
			parallelBatches: options.parallelBatches || 3,
			offlineQueueLimit: options.offlineQueueLimit || 5000,
			...options,
		};

		// Initialize orchestrated runner for all sync operations
		const orchestrator = this.#managers?.asyncOrchestrator;
		if (!orchestrator) {
			throw new this.#AppError(
				"AsyncOrchestrationService required for BatchSync observability compliance"
			);
		}

		this.#orchestratorRunner = orchestrator.createRunner({
			labelPrefix: "sync.batch",
			actorId: "sync.batch",
			eventType: "SYNC_BATCH_OPERATION",
			meta: { component: "BatchSync" },
		});

		this.#validateSyncLicense();
	}

	/**
	 * Validates enterprise license for sync management features.
	 * @private
	 */
	#validateSyncLicense() {
		const license = this.#managers?.license;
		if (!license?.hasFeature("sync_management")) {
			this.#dispatchAction("license.validation_failed", {
				feature: "sync_management",
				component: "BatchSync",
			});
			throw new this.#PolicyError(
				"Enterprise license required for BatchSync"
			);
		}
	}

	/**
	 * Centralized orchestration wrapper for consistent observability and policy enforcement.
	 * @private
	 * @param {string} operationName - Operation identifier for metrics and logging
	 * @param {Function} operation - Synchronous function that returns a Promise to execute
	 * @param {object} [options={}] - Additional orchestrator options
	 * @returns {Promise<any>}
	 */
	#runOrchestrated(operationName, operation, options = {}) {
		// Policy enforcement
		if (!this.#policies?.getPolicy("sync", "enabled")) {
			this.#dispatchAction("sync.policy_disabled", {
				operation: operationName,
			});
			return Promise.resolve(null);
		}

		try {
			/* PERFORMANCE_BUDGET: 5ms */
			return this.#orchestratorRunner.run(
				() =>
					this.#errorBoundary?.try(() => operation()) || operation(),
				{
					label: `sync.batch.${operationName}`,
					classification: "INTERNAL",
					...options,
				}
			);
		} catch (error) {
			this.#dispatchAction("sync.orchestration_failed", {
				operation: operationName,
				error: error.message,
			});
			throw error;
		}
	}

	/**
	 * Initializes the module and starts the background batch processor.
	 * The processor periodically checks for and sends batches that have reached their maximum age.
	 * @returns {Promise<this>} The initialized instance.
	 */
	init() {
		return this.#runOrchestrated(
			"init",
			() => {
				this.#startBatchProcessor();
				return this;
			},
			{ eventType: "SYNC_BATCH_INIT" }
		);
	}

	/**
	 * Stops the background batch processor and cleans up resources.
	 * @returns {Promise<this>}
	 */
	/**
	 * TODO: Add JSDoc for method destroy
	 * @memberof AutoGenerated
	 */
	destroy() {
		return this.#runOrchestrated("destroy", () => {
			this.#executeDestroy();
			return this;
		});
	}

	#executeDestroy() {
		if (this.#batchProcessorInterval) {
			clearInterval(this.#batchProcessorInterval);
			this.#batchProcessorInterval = null;
		}
		return this;
	}

	/**
	 * Pushes an array of items to the server, automatically grouping them into efficient batches.
	 * It processes batches in parallel to improve throughput.
	 * @param {object} options - The push operation options.
	 * @param {Array<object>} [options.items=[]] - The array of items to push.
	 * @param {string} [options.operation='update'] - The default operation type for the items.
	 * @returns {Promise<object>} A summary of the push operation, including counts of pushed/failed items and batch results.
	 */
	push(options) {
		return this.#runOrchestrated("push", () => this.#executePush(options), {
			eventType: "SYNC_BATCH_PUSH",
			meta: {
				itemCount: options?.items?.length ?? 0,
				operation: options?.operation ?? "update",
			},
		});
	}

	async #executePush(options) {
		const { items = [], operation = "update" } = options;

		// Group items by operation type for optimal batching
		const groupedItems = this.#groupItemsByOperation(items, operation);
		const results = [];

		// Process each group in batches
		/* PERFORMANCE_BUDGET: 200ms */
		for (const [op, groupItems] of groupedItems.entries()) {
			const batches = this.#createBatches(
				groupItems,
				this.#config.batchSize
			);

			const batchPromises = batches.map((batch) =>
				this.#processPushBatch(batch, op)
			);
			const batchResults = await this.#processInParallel(
				batchPromises,
				this.#config.parallelBatches
			);
			results.push(...batchResults);
		}

		const summary = {
			pushed: results.reduce(
				(s, r) => s + (r.success ? r.itemCount : 0),
				0
			),
			failed: results.reduce(
				(s, r) => s + (r.success ? 0 : r.itemCount),
				0
			),
			batches: results.length,
			results,
		};
		return summary;
	}

	/**
	 * Pulls a batch of data from the server.
	 * @param {object} options - The pull operation options.
	 * @param {string[]} [options.entityTypes=[]] - The types of entities to pull.
	 * @param {string|number} [options.since] - A timestamp or token indicating the last sync point.
	 * @param {number} [options.limit] - The maximum number of items to pull.
	 * @returns {Promise<{pulled: number, items: Array<object>, hasMore: boolean, nextToken: string|null}>} The pulled data and pagination info.
	 */
	pull(options) {
		return this.#runOrchestrated("pull", () => this.#executePull(options), {
			eventType: "SYNC_BATCH_PULL",
			meta: {
				entityTypes: options?.entityTypes ?? [],
				since: options?.since ?? null,
			},
		});
	}

	async #executePull(options) {
		const { entityTypes = [], since, limit } = options;

		try {
			/* PERFORMANCE_BUDGET: 100ms */
			const batchRequest = {
				entityTypes,
				since,
				limit,
				batchSize: this.#config.batchSize,
			};
			const response = await this.#sendBatchPullRequest(batchRequest);

			const result = {
				pulled: response.items?.length || 0,
				items: response.items || [],
				hasMore: response.hasMore || false,
				nextToken: response.nextToken || null,
			};

			return result;
		} catch (error) {
			const appError = new this.#AppError("Batch pull failed", {
				cause: error,
				context: { entityTypes, since },
			});
			throw appError;
		}
	}

	/**
	 * Adds an item to the offline synchronization queue.
	 * The queue is automatically flushed when it reaches the configured batch size.
	 * @param {object} item - The item to queue.
	 * @param {string} [operation='update'] - The operation type for this item (e.g., 'create', 'update', 'delete').
	 */
	queueItem(item, operation = "update") {
		// Mandate 4.1: Enforce a limit on the offline queue to prevent unbounded memory growth.
		if (this.#syncQueue.length >= this.#config.offlineQueueLimit) {
			this.#dispatchAction("sync.batch.queue_full", {
				itemId: item.id,
				queueLimit: this.#config.offlineQueueLimit,
			});
			return;
		}

		this.#syncQueue.push({
			item,
			operation,
			timestamp: DateCore.timestamp(),
		});
		this.#dispatchAction("sync.batch.item_queued", {
			itemId: item.id,
			operation,
		});

		// Auto-flush if queue is full
		/**

		 * TODO: Add JSDoc for method if

		 * @memberof AutoGenerated

		 */

		if (this.#syncQueue.length >= this.#config.batchSize) {
			this.flushQueue();
		}
	}

	/**
	 * Manually flushes all items currently in the offline queue by processing them as a push operation. This is useful for "sync now" functionality.
	 * @returns {Promise<object>} The result of the push operation.
	 */
	flushQueue() {
		return this.#runOrchestrated(
			"flushQueue",
			() => this.#executeFlushQueue(),
			{ eventType: "SYNC_BATCH_FLUSH_QUEUE" }
		);
	}

	async #executeFlushQueue() {
		if (this.#syncQueue.length === 0)
			return { pushed: 0, failed: 0, batches: 0, results: [] };

		const items = this.#syncQueue.splice(0);
		return this.#executePush({
			items: items.map((i) => i.item),
			operation: "mixed", // Mixed operations in queue
		});
	}

	/**
	 * Syncs a single item by adding it to the batch queue for later processing.
	 * This method is part of the sync module interface but is adapted for batching.
	 * @param {object} item - The item to sync.
	 * @param {string} operation - The operation type.
	 * @returns {Promise<{queued: boolean, batchPending: boolean}>} A promise that resolves immediately, indicating the item has been queued.
	 */
	syncItem(item, operation) {
		return this.#runOrchestrated(
			"syncItem",
			() => {
				this.queueItem(item, operation);
				return Promise.resolve({ queued: true, batchPending: true });
			},
			{
				eventType: "SYNC_BATCH_SYNC_ITEM",
				meta: { itemId: item?.id, operation },
			}
		);
	}

	/**
	 * Checks if an item is supported by this sync module.
	 * @param {object} item - The item to check.
	 * @returns {boolean} Always returns true as BatchSync supports all item types.
	 */
	supportsItem(_item) {
		return true; // Batch sync supports all items
	}

	/**
	 * Get batch metrics
	 * @returns {object} An object containing performance and state metrics for the batch sync process.
	 */
	getStatus() {
		return {
			...(this.#metrics?.getAllAsObject() || {}),
			queueSize: this.#syncQueue.length,
			pendingBatches: this.#pendingBatches.size,
		};
	}

	// Private methods
	/**
	 * Starts a timer that periodically processes batches that have exceeded their maximum age.
	 * @private
	 */
	#startBatchProcessor() {
		this.#batchProcessorInterval = setInterval(() => {
			this.#processAgedBatches();
		}, 5000); // Check every 5 seconds
	}

	/**
	 * Iterates through pending batches and processes any that are older than the configured `maxBatchAge`.
	 * @private
	 */
	#processAgedBatches() {
		const now = DateCore.timestamp();

		for (const [batchId, batch] of this.#pendingBatches.entries()) {
			if (now - batch.createdAt > this.#config.maxBatchAge) {
				this.#processPendingBatch(batchId);
			}
		}
	}

	/**
	 * Processes a single pending batch by its ID.
	 * @private
	 * @param {string} batchId - The ID of the batch to process.
	 */
	async #processPendingBatch(batchId) {
		const batch = this.#pendingBatches.get(batchId);
		if (!batch) return;

		this.#pendingBatches.delete(batchId);

		// Use orchestrator for background processing
		this.#runOrchestrated(
			"processAgedBatch",
			() => this.#processPushBatch(batch.items, batch.operation),
			{ meta: { batchId } }
		);
	}

	/**
	 * Processes a single batch of items for a push operation.
	 * This includes optional compression and sending the request to the server.
	 * @private
	 * @param {Array<object>} items - The items in the batch.
	 * @param {string} operation - The operation type for this batch.
	 * @returns {Promise<object>} A result object for the processed batch.
	 */
	async #processPushBatch(items, operation) {
		const batchId = this.#generateBatchId();

		try {
			/* PERFORMANCE_BUDGET: 50ms */
			// Prepare batch payload
			let payload = {
				batchId,
				operation,
				items,
				timestamp: DateCore.timestamp(),
			};

			// Compress if beneficial
			if (this.#config.enableCompression) {
				payload = await this.#compressBatch(payload);
			}

			// Send batch to server
			await this.#sendBatchRequest(payload);

			return {
				batchId,
				success: true,
				itemCount: items.length,
				compressed: payload.compressed || false,
			};
		} catch (error) {
			this.#dispatchAction("sync.batch.push_failed", {
				batchId,
				itemCount: items.length,
				error: error.message,
			});

			return {
				batchId,
				success: false, // V8.0 Parity: Standardize error reporting.
				itemCount: items.length,
				error: error.message,
			};
		}
	}

	/**
	 * Groups an array of items by their operation type.
	 * @private
	 * @param {Array<object>} items - The items to group.
	 * @param {string} defaultOperation - The operation to use if an item doesn't specify one.
	 * @returns {Map<string, Array<object>>} A map where keys are operation types and values are arrays of items.
	 */
	#groupItemsByOperation(items, defaultOperation) {
		const groups = new Map();

		for (const item of items) {
			const operation = item._operation || defaultOperation;

			if (!groups.has(operation)) {
				groups.set(operation, []);
			}

			groups.get(operation).push(item);
		}

		return groups;
	}

	/**
	 * Splits a larger array of items into smaller batches based on the configured batch size.
	 * @private
	 * @param {Array<object>} items - The array of items to split.
	 * @param {number} batchSize - The maximum size of each batch.
	 * @returns {Array<Array<object>>} An array of smaller batch arrays.
	 */
	#createBatches(items, batchSize) {
		const batches = [];

		for (let i = 0; i < items.length; i += batchSize) {
			batches.push(items.slice(i, i + batchSize));
		}

		this.#dispatchAction("sync.batch.created", {
			batchSize,
			batchCount: batches.length,
		}).catch(() => {
			/* no-op */
		});

		return batches;
	}

	/**
	 * A utility to execute an array of promises in parallel with a concurrency limit.
	 * @private
	 * @param {Array<Promise>} promises - The array of promises to execute.
	 * @param {number} limit - The maximum number of promises to run concurrently.
	 * @returns {Promise<Array<object>>} A promise that resolves with an array of all results.
	 */
	async #processInParallel(promises, limit) {
		const results = [];

		/* PERFORMANCE_BUDGET: 500ms */
		for (let i = 0; i < promises.length; i += limit) {
			const batch = promises.slice(i, i + limit);
			const batchResults = await Promise.allSettled(batch);

			results.push(
				...batchResults.map((r) =>
					r.status === "fulfilled"
						? r.value
						: { success: false, error: r.reason?.message }
				)
			);
		}

		return results;
	}

	/**
	 * Compresses a batch payload if it exceeds the configured size threshold.
	 * @private
	 * @param {object} payload - The batch payload to potentially compress.
	 * @returns {Promise<object>} The original or compressed payload.
	 */
	async #compressBatch(payload) {
		const payloadString = JSON.stringify(payload);

		/* PERFORMANCE_BUDGET: 20ms */
		if (payloadString.length < this.#config.compressionThreshold) {
			return payload;
		}

		try {
			// Simple compression using gzip (in real implementation)
			// For demo, just mark as compressed
			const originalSize = payloadString.length;
			const compressedSize = Math.floor(originalSize * 0.7); // Simulate 30% compression

			return {
				...payload,
				compressed: true,
				originalSize,
				compressedSize,
				data: `compressed:${payloadString}`, // Simulate compressed data
			};
		} catch (error) {
			this.#dispatchAction("sync.batch.compression_failed", {
				batchId: payload.batchId,
				error: error.message,
			});
			return payload;
		}
	}

	/**
	 * Simulates sending a push batch request to a server API.
	 * @private
	 * @param {object} payload - The payload to send.
	 * @returns {Promise<object>} A promise that simulates the server response.
	 */
	async #sendBatchRequest(payload) {
		/* PERFORMANCE_BUDGET: 500ms */
		// Simulate API call
		return new Promise((resolve, reject) => {
			setTimeout(
				() => {
					// Simulate success/failure
					if (Math.random() > 0.1) {
						// 90% success rate
						resolve({
							batchId: payload.batchId,
							processed: payload.items?.length || 0,
							status: "success",
						});
					} else {
						reject(new Error("Batch processing failed"));
					}
				},
				200 + Math.random() * 300
			); // 200-500ms latency
		});
	}

	/**
	 * Simulates sending a pull batch request to a server API.
	 * @private
	 * @param {object} request - The request parameters.
	 * @returns {Promise<object>} A promise that simulates the server response with pulled data.
	 */
	async #sendBatchPullRequest(request) {
		/* PERFORMANCE_BUDGET: 350ms */
		// Simulate API call for pulling data
		return new Promise((resolve) => {
			setTimeout(
				() => {
					// Simulate returning some items
					const items = Array.from(
						{ length: Math.min(request.batchSize, 25) },
						(_, i) => ({
							id: `item_${Date.now()}_${i}`,
							entity_type: request.entityTypes[0] || "object",
							content: `Batch pulled item ${i}`,
							updated_at: DateCore.iso(),
						})
					);

					resolve({
						items,
						hasMore: items.length === request.batchSize,
						nextToken:
							items.length > 0 ? `token_${Date.now()}` : null,
					});
				},
				150 + Math.random() * 200
			); // 150-350ms latency
		});
	}

	/**
	 * Generates a unique identifier for a batch.
	 * @private
	 * @returns {string} A unique batch ID string.
	 */
	#generateBatchId() {
		return `batch_${DateCore.timestamp()}_${Math.random().toString(36).substr(2, 6)}`;
	}

	/**
	 * Dispatches an action through the ActionDispatcher for observability.
	 * @private
	 * @param {string} actionType - Type of action to dispatch
	 * @param {object} payload - Action payload
	 */
	#dispatchAction(actionType, payload) {
		try {
			this.#actionDispatcher?.dispatch(actionType, { ...payload });
		} catch (error) {
			console.error(
				`[BatchSync] Failed to dispatch action: ${actionType}`,
				error
			);
		}
	}
}
